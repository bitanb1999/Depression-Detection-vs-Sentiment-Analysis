{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-06-26T14:50:44.572437Z","iopub.execute_input":"2022-06-26T14:50:44.573128Z","iopub.status.idle":"2022-06-26T14:50:44.587525Z","shell.execute_reply.started":"2022-06-26T14:50:44.573070Z","shell.execute_reply":"2022-06-26T14:50:44.586155Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"df=pd.read_csv(\"../input/suicide-watch/Suicide_Detection.csv\")\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-26T14:50:46.775470Z","iopub.execute_input":"2022-06-26T14:50:46.775820Z","iopub.status.idle":"2022-06-26T14:50:50.892122Z","shell.execute_reply.started":"2022-06-26T14:50:46.775791Z","shell.execute_reply":"2022-06-26T14:50:50.890983Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"!pip install bs4","metadata":{"execution":{"iopub.status.busy":"2022-06-26T08:21:15.294184Z","iopub.execute_input":"2022-06-26T08:21:15.295516Z","iopub.status.idle":"2022-06-26T08:21:28.333584Z","shell.execute_reply.started":"2022-06-26T08:21:15.295469Z","shell.execute_reply":"2022-06-26T08:21:28.332368Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport sklearn\nimport sklearn.ensemble\nimport sklearn.metrics\nfrom sklearn.utils import shuffle\nfrom io import StringIO\nimport re\nfrom bs4 import BeautifulSoup","metadata":{"execution":{"iopub.status.busy":"2022-06-26T14:50:51.371779Z","iopub.execute_input":"2022-06-26T14:50:51.372179Z","iopub.status.idle":"2022-06-26T14:50:52.627900Z","shell.execute_reply.started":"2022-06-26T14:50:51.372146Z","shell.execute_reply":"2022-06-26T14:50:52.626929Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"from nltk.corpus import stopwords\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\nimport lime\nfrom lime import lime_text\nfrom lime.lime_text import LimeTextExplainer\nfrom sklearn.pipeline import make_pipeline","metadata":{"execution":{"iopub.status.busy":"2022-06-26T14:50:55.329589Z","iopub.execute_input":"2022-06-26T14:50:55.329976Z","iopub.status.idle":"2022-06-26T14:50:55.710072Z","shell.execute_reply.started":"2022-06-26T14:50:55.329942Z","shell.execute_reply":"2022-06-26T14:50:55.709124Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"df = df[pd.notnull(df['class'])]\ndf = df.sample(frac=0.5, random_state=99).reset_index(drop=True)\ndf = shuffle(df, random_state=22)\ndf = df.reset_index(drop=True)\ndf['class_label'] = df['class'].factorize()[0]\nclass_label_df = df[['class', 'class_label']].drop_duplicates().sort_values('class_label')\nlabel_to_id = dict(class_label_df.values)\nid_to_label = dict(class_label_df[['class_label', 'class']].values)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T14:51:27.846145Z","iopub.execute_input":"2022-06-26T14:51:27.846548Z","iopub.status.idle":"2022-06-26T14:51:27.981111Z","shell.execute_reply.started":"2022-06-26T14:51:27.846515Z","shell.execute_reply":"2022-06-26T14:51:27.980133Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\nBAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')","metadata":{"execution":{"iopub.status.busy":"2022-06-26T14:51:35.406580Z","iopub.execute_input":"2022-06-26T14:51:35.406947Z","iopub.status.idle":"2022-06-26T14:51:35.413699Z","shell.execute_reply.started":"2022-06-26T14:51:35.406915Z","shell.execute_reply":"2022-06-26T14:51:35.412326Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def clean_text(text):\n    \"\"\"\n        text: a string\n        \n        return: modified initial string\n    \"\"\"\n    text = BeautifulSoup(text, \"lxml\").text # HTML decoding. BeautifulSoup's text attribute will return a string stripped of any HTML tags and metadata.\n    text = text.lower() # lowercase text\n    text = REPLACE_BY_SPACE_RE.sub(' ', text) # replace REPLACE_BY_SPACE_RE symbols by space in text. substitute the matched string in REPLACE_BY_SPACE_RE with space.\n    text = BAD_SYMBOLS_RE.sub('', text) # remove symbols which are in BAD_SYMBOLS_RE from text. substitute the matched string in BAD_SYMBOLS_RE with nothing. \n#    text = ' '.join(word for word in text.split() if word not in STOPWORDS) # remove stopwors from text\n    return text","metadata":{"execution":{"iopub.status.busy":"2022-06-26T14:51:39.241444Z","iopub.execute_input":"2022-06-26T14:51:39.241867Z","iopub.status.idle":"2022-06-26T14:51:39.249187Z","shell.execute_reply.started":"2022-06-26T14:51:39.241833Z","shell.execute_reply":"2022-06-26T14:51:39.247557Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"df['text'] = df['text'].apply(clean_text)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T14:51:39.628070Z","iopub.execute_input":"2022-06-26T14:51:39.628796Z","iopub.status.idle":"2022-06-26T14:52:06.399533Z","shell.execute_reply.started":"2022-06-26T14:51:39.628760Z","shell.execute_reply":"2022-06-26T14:52:06.398527Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"list_corpus = df[\"text\"].tolist()\nlist_labels = df[\"class_label\"].tolist()\nX_train, X_test, y_train, y_test = train_test_split(list_corpus, list_labels, test_size=0.2, random_state=40)\nvectorizer = CountVectorizer(analyzer='word',token_pattern=r'\\w{1,}', ngram_range=(1, 3), stop_words = 'english', binary=True)\ntrain_vectors = vectorizer.fit_transform(X_train)\ntest_vectors = vectorizer.transform(X_test)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T14:53:07.469542Z","iopub.execute_input":"2022-06-26T14:53:07.470298Z","iopub.status.idle":"2022-06-26T14:54:05.369662Z","shell.execute_reply.started":"2022-06-26T14:53:07.470255Z","shell.execute_reply":"2022-06-26T14:54:05.368621Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"logreg = LogisticRegression(n_jobs=1, C=1e5)\nlogreg.fit(train_vectors, y_train)\npred = logreg.predict(test_vectors)\naccuracy = accuracy_score(y_test, pred)\nprecision = precision_score(y_test, pred, average='weighted')\nrecall = recall_score(y_test, pred, average='weighted')\nf1 = f1_score(y_test, pred, average='weighted')\nprint(\"accuracy = %.3f, precision = %.3f, recall = %.3f, f1 = %.3f\" % (accuracy, precision, recall, f1))","metadata":{"execution":{"iopub.status.busy":"2022-06-26T08:22:51.520627Z","iopub.execute_input":"2022-06-26T08:22:51.520914Z","iopub.status.idle":"2022-06-26T08:25:33.392438Z","shell.execute_reply.started":"2022-06-26T08:22:51.520888Z","shell.execute_reply":"2022-06-26T08:25:33.391352Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-26T14:54:05.371665Z","iopub.execute_input":"2022-06-26T14:54:05.371963Z","iopub.status.idle":"2022-06-26T14:54:05.385425Z","shell.execute_reply.started":"2022-06-26T14:54:05.371937Z","shell.execute_reply":"2022-06-26T14:54:05.384352Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"c = make_pipeline(vectorizer, logreg)\nclass_names=list(df['class'].unique())\nexplainer = LimeTextExplainer(class_names=class_names)\n\nidx = 1877\nexp = explainer.explain_instance(X_test[idx], c.predict_proba, num_features=6, labels=[0,1])\nprint('Document id: %d' % idx)\nprint('Predicted class =', class_names[logreg.predict(test_vectors[idx]).reshape(1,-1)[0,0]])\nprint('True class: %s' % class_names[y_test[idx]])","metadata":{"execution":{"iopub.status.busy":"2022-06-26T08:25:33.407661Z","iopub.execute_input":"2022-06-26T08:25:33.408261Z","iopub.status.idle":"2022-06-26T08:25:42.942015Z","shell.execute_reply.started":"2022-06-26T08:25:33.408225Z","shell.execute_reply":"2022-06-26T08:25:42.941021Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"print ('Explanation for class %s' % class_names[0])\nprint ('\\n'.join(map(str, exp.as_list(label=0))))","metadata":{"execution":{"iopub.status.busy":"2022-06-26T08:25:42.943510Z","iopub.execute_input":"2022-06-26T08:25:42.944116Z","iopub.status.idle":"2022-06-26T08:25:42.951995Z","shell.execute_reply.started":"2022-06-26T08:25:42.944064Z","shell.execute_reply":"2022-06-26T08:25:42.951060Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"exp = explainer.explain_instance(X_test[idx], c.predict_proba, num_features=6, top_labels=2)\nprint(exp.available_labels())","metadata":{"execution":{"iopub.status.busy":"2022-06-26T08:25:42.953566Z","iopub.execute_input":"2022-06-26T08:25:42.954498Z","iopub.status.idle":"2022-06-26T08:25:50.941056Z","shell.execute_reply.started":"2022-06-26T08:25:42.954456Z","shell.execute_reply":"2022-06-26T08:25:50.940035Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"exp.show_in_notebook(text=False)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T08:25:50.942339Z","iopub.execute_input":"2022-06-26T08:25:50.943231Z","iopub.status.idle":"2022-06-26T08:25:51.035071Z","shell.execute_reply.started":"2022-06-26T08:25:50.943194Z","shell.execute_reply":"2022-06-26T08:25:51.033887Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"!pip install transformers pytorch-transformers","metadata":{"execution":{"iopub.status.busy":"2022-06-26T14:54:05.386978Z","iopub.execute_input":"2022-06-26T14:54:05.387590Z","iopub.status.idle":"2022-06-26T14:54:16.265558Z","shell.execute_reply.started":"2022-06-26T14:54:05.387552Z","shell.execute_reply":"2022-06-26T14:54:16.264406Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"!apt install git-lfs\n!git config --global credential.helper store\nfrom huggingface_hub import notebook_login\n\nnotebook_login()","metadata":{"execution":{"iopub.status.busy":"2022-06-26T08:26:00.930245Z","iopub.execute_input":"2022-06-26T08:26:00.930633Z","iopub.status.idle":"2022-06-26T08:26:14.159043Z","shell.execute_reply.started":"2022-06-26T08:26:00.930593Z","shell.execute_reply":"2022-06-26T08:26:14.158005Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"!pip install torch","metadata":{"execution":{"iopub.status.busy":"2022-06-26T14:54:16.269161Z","iopub.execute_input":"2022-06-26T14:54:16.269548Z","iopub.status.idle":"2022-06-26T14:54:25.405949Z","shell.execute_reply.started":"2022-06-26T14:54:16.269515Z","shell.execute_reply":"2022-06-26T14:54:25.404741Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"import torch\ntorch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2022-06-26T14:54:25.407638Z","iopub.execute_input":"2022-06-26T14:54:25.408024Z","iopub.status.idle":"2022-06-26T14:54:27.074513Z","shell.execute_reply.started":"2022-06-26T14:54:25.407983Z","shell.execute_reply":"2022-06-26T14:54:27.073479Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"import transformers\nfrom transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup\nimport torch\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom pylab import rcParams\nimport matplotlib.pyplot as plt\nfrom matplotlib import rc\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom collections import defaultdict\nfrom textwrap import wrap\nfrom torch import nn, optim\nfrom torch.utils.data import Dataset, DataLoader\n%matplotlib inline\n%config InlineBackend.figure_format='retina'\nsns.set(style='whitegrid', palette='muted', font_scale=1.2)\nHAPPY_COLORS_PALETTE = [\"#01BEFE\", \"#FFDD00\", \"#FF7D00\", \"#FF006D\", \"#ADFF02\", \"#8F00FF\"]\nsns.set_palette(sns.color_palette(HAPPY_COLORS_PALETTE))\nrcParams['figure.figsize'] = 12, 8\nRANDOM_SEED = 42\nnp.random.seed(RANDOM_SEED)\ntorch.manual_seed(RANDOM_SEED)\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2022-06-26T14:54:27.077006Z","iopub.execute_input":"2022-06-26T14:54:27.078442Z","iopub.status.idle":"2022-06-26T14:54:32.274257Z","shell.execute_reply.started":"2022-06-26T14:54:27.078394Z","shell.execute_reply":"2022-06-26T14:54:32.273211Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"execution":{"iopub.status.busy":"2022-06-26T14:54:32.276230Z","iopub.execute_input":"2022-06-26T14:54:32.276859Z","iopub.status.idle":"2022-06-26T14:54:32.292480Z","shell.execute_reply.started":"2022-06-26T14:54:32.276815Z","shell.execute_reply":"2022-06-26T14:54:32.291278Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ndf_train,df_test=train_test_split(df[['text','class_label']],train_size=0.7,random_state=23,shuffle=True, stratify=df['class_label'])","metadata":{"execution":{"iopub.status.busy":"2022-06-26T14:54:32.294191Z","iopub.execute_input":"2022-06-26T14:54:32.294750Z","iopub.status.idle":"2022-06-26T14:54:32.414892Z","shell.execute_reply.started":"2022-06-26T14:54:32.294709Z","shell.execute_reply":"2022-06-26T14:54:32.413924Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"df_train.class_label.value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-06-26T14:54:32.417346Z","iopub.execute_input":"2022-06-26T14:54:32.418069Z","iopub.status.idle":"2022-06-26T14:54:32.428350Z","shell.execute_reply.started":"2022-06-26T14:54:32.418026Z","shell.execute_reply":"2022-06-26T14:54:32.427153Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"label_dict={}\nl=0;\nfor i in ['suicide','non-suicide']:\n  label_dict[i]=l\n  l+=1\nlabel_dict","metadata":{"execution":{"iopub.status.busy":"2022-06-26T14:54:32.432906Z","iopub.execute_input":"2022-06-26T14:54:32.433262Z","iopub.status.idle":"2022-06-26T14:54:32.442271Z","shell.execute_reply.started":"2022-06-26T14:54:32.433232Z","shell.execute_reply":"2022-06-26T14:54:32.441031Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"import nltk\nnltk.download('vader_lexicon')\nimport pandas as pd\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer\nsent = SentimentIntensityAnalyzer()\npolarity = [round(sent.polarity_scores(i)['compound'], 2) for i in df_train['text']]\ndf_train['sentiment_score'] = polarity\ndf_train.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-26T08:26:23.916221Z","iopub.execute_input":"2022-06-26T08:26:23.917137Z","iopub.status.idle":"2022-06-26T08:28:37.999160Z","shell.execute_reply.started":"2022-06-26T08:26:23.917076Z","shell.execute_reply":"2022-06-26T08:28:37.998131Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"polarity = [round(sent.polarity_scores(i)['compound'], 2) for i in df_test['text']]\ndf_test['sentiment_score'] = polarity\ndf_test.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-26T08:28:38.000600Z","iopub.execute_input":"2022-06-26T08:28:38.001207Z","iopub.status.idle":"2022-06-26T08:29:33.617854Z","shell.execute_reply.started":"2022-06-26T08:28:38.001170Z","shell.execute_reply":"2022-06-26T08:29:33.616479Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"bert_model = BertModel.from_pretrained('bert-base-uncased')\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\ntoken_lens = []\nfor txt in df_train.text:\n  tokens = tokenizer.encode(txt, max_length=512)\n  token_lens.append(len(tokens))","metadata":{"execution":{"iopub.status.busy":"2022-06-26T08:29:33.619475Z","iopub.execute_input":"2022-06-26T08:29:33.619849Z","iopub.status.idle":"2022-06-26T08:35:21.930946Z","shell.execute_reply.started":"2022-06-26T08:29:33.619813Z","shell.execute_reply":"2022-06-26T08:35:21.929919Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"sns.distplot(token_lens)\n#plt.xlim([0, 256]);\nplt.xlabel('Token count');","metadata":{"execution":{"iopub.status.busy":"2022-06-26T08:38:21.382987Z","iopub.execute_input":"2022-06-26T08:38:21.383911Z","iopub.status.idle":"2022-06-26T08:38:22.136052Z","shell.execute_reply.started":"2022-06-26T08:38:21.383871Z","shell.execute_reply":"2022-06-26T08:38:22.135045Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"MAX_LEN = 512\nclass GPSentimentDataset(Dataset):\n  def __init__(self, texts, targets, tokenizer, max_len):\n    self.texts = texts\n    self.targets = targets\n    self.tokenizer = tokenizer\n    self.max_len = max_len\n  def __len__(self):\n    return len(self.texts)\n  def __getitem__(self, item):\n    text = str(self.texts[item])\n    target = self.targets[item]\n    encoding = self.tokenizer.encode_plus(\n      text,\n      add_special_tokens=True,\n      max_length=self.max_len,\n      return_token_type_ids=False,\n      pad_to_max_length=True,\n      return_attention_mask=True,\n      return_tensors='pt',\n    )\n    return {\n      'text': text,\n      'input_ids': encoding['input_ids'].flatten(),\n      'attention_mask': encoding['attention_mask'].flatten(),\n      'targets': torch.tensor(target, dtype=torch.long)\n    }","metadata":{"execution":{"iopub.status.busy":"2022-06-26T14:54:32.443919Z","iopub.execute_input":"2022-06-26T14:54:32.444295Z","iopub.status.idle":"2022-06-26T14:54:32.454577Z","shell.execute_reply.started":"2022-06-26T14:54:32.444257Z","shell.execute_reply":"2022-06-26T14:54:32.453588Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"df_test, df_val = train_test_split(\n  df_test[['text','class_label']],\n  train_size=0.5,\n  random_state=RANDOM_SEED\n)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T14:54:32.456158Z","iopub.execute_input":"2022-06-26T14:54:32.456525Z","iopub.status.idle":"2022-06-26T14:54:32.474262Z","shell.execute_reply.started":"2022-06-26T14:54:32.456486Z","shell.execute_reply":"2022-06-26T14:54:32.473036Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"def create_data_loader(df, tokenizer, max_len, batch_size):\n  ds = GPSentimentDataset(\n    texts=df.text.to_numpy(),\n    targets=df.class_label.to_numpy(),\n    tokenizer=tokenizer,\n    max_len=max_len\n  )\n  return DataLoader(\n    ds,\n    batch_size=batch_size,\n    num_workers=4\n  )","metadata":{"execution":{"iopub.status.busy":"2022-06-26T14:54:32.475573Z","iopub.execute_input":"2022-06-26T14:54:32.476075Z","iopub.status.idle":"2022-06-26T14:54:32.482756Z","shell.execute_reply.started":"2022-06-26T14:54:32.476035Z","shell.execute_reply":"2022-06-26T14:54:32.481684Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"BATCH_SIZE = 8\ntrain_data_loader = create_data_loader(df_train, tokenizer, MAX_LEN, BATCH_SIZE)\nval_data_loader = create_data_loader(df_val, tokenizer, MAX_LEN, BATCH_SIZE)\ntest_data_loader = create_data_loader(df_test, tokenizer, MAX_LEN, BATCH_SIZE)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T14:54:32.484281Z","iopub.execute_input":"2022-06-26T14:54:32.485235Z","iopub.status.idle":"2022-06-26T14:54:32.763382Z","shell.execute_reply.started":"2022-06-26T14:54:32.485197Z","shell.execute_reply":"2022-06-26T14:54:32.761966Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"data = next(iter(train_data_loader))\ndata.keys()","metadata":{"execution":{"iopub.status.busy":"2022-06-26T14:54:32.764535Z","iopub.status.idle":"2022-06-26T14:54:32.765496Z","shell.execute_reply.started":"2022-06-26T14:54:32.765197Z","shell.execute_reply":"2022-06-26T14:54:32.765226Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(data['input_ids'].shape)\nprint(data['attention_mask'].shape)\nprint(data['targets'].shape)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T14:54:32.767322Z","iopub.status.idle":"2022-06-26T14:54:32.767831Z","shell.execute_reply.started":"2022-06-26T14:54:32.767571Z","shell.execute_reply":"2022-06-26T14:54:32.767596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class SentimentClassifier(nn.Module):\n  def __init__(self, n_classes):\n    super(SentimentClassifier, self).__init__()\n    self.bert = BertModel.from_pretrained('bert-base-uncased')\n    self.drop = nn.Dropout(p=0.3)\n    self.out = nn.Linear(self.bert.config.hidden_size, n_classes)\n  def forward(self, input_ids, attention_mask):\n    _, pooled_output = self.bert(\n      input_ids=input_ids,\n      attention_mask=attention_mask,return_dict=False\n    )\n    output = self.drop(pooled_output,)\n    return self.out(output)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T14:54:32.769376Z","iopub.status.idle":"2022-06-26T14:54:32.770324Z","shell.execute_reply.started":"2022-06-26T14:54:32.770036Z","shell.execute_reply":"2022-06-26T14:54:32.770065Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = SentimentClassifier(2)\nmodel = model.to(device)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T14:54:32.771897Z","iopub.status.idle":"2022-06-26T14:54:32.772407Z","shell.execute_reply.started":"2022-06-26T14:54:32.772145Z","shell.execute_reply":"2022-06-26T14:54:32.772170Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_ids = data['input_ids'].to(device)\nattention_mask = data['attention_mask'].to(device)\nprint(input_ids.shape) # batch size x seq length\nprint(attention_mask.shape)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T14:54:32.773725Z","iopub.status.idle":"2022-06-26T14:54:32.774577Z","shell.execute_reply.started":"2022-06-26T14:54:32.774292Z","shell.execute_reply":"2022-06-26T14:54:32.774321Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"EPOCHS = 4\noptimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False)\ntotal_steps = len(train_data_loader) * EPOCHS\nscheduler = get_linear_schedule_with_warmup(\n  optimizer,\n  num_warmup_steps=0,\n  num_training_steps=total_steps\n)\nloss_fn = nn.CrossEntropyLoss().to(device)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T08:54:00.965793Z","iopub.execute_input":"2022-06-26T08:54:00.966301Z","iopub.status.idle":"2022-06-26T08:54:00.979197Z","shell.execute_reply.started":"2022-06-26T08:54:00.966265Z","shell.execute_reply":"2022-06-26T08:54:00.978147Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"def train_epoch(\n  model,\n  data_loader,\n  loss_fn,\n  optimizer,\n  device,\n  scheduler,\n  n_examples\n):\n  model = model.train()\n  losses = []\n  correct_predictions = 0\n  for d in data_loader:\n    input_ids = d[\"input_ids\"].to(device)\n    attention_mask = d[\"attention_mask\"].to(device)\n    targets = d[\"targets\"].to(device)\n    outputs = model(\n      input_ids=input_ids,\n      attention_mask=attention_mask\n    )\n    _, preds = torch.max(outputs, dim=1)\n    loss = loss_fn(outputs, targets)\n    correct_predictions += torch.sum(preds == targets)\n    losses.append(loss.item())\n    loss.backward()\n    nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n    optimizer.step()\n    scheduler.step()\n    optimizer.zero_grad()\n  return correct_predictions.double() / n_examples, np.mean(losses)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T08:54:27.818992Z","iopub.execute_input":"2022-06-26T08:54:27.819597Z","iopub.status.idle":"2022-06-26T08:54:27.829902Z","shell.execute_reply.started":"2022-06-26T08:54:27.819561Z","shell.execute_reply":"2022-06-26T08:54:27.828853Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"def eval_model(model, data_loader, loss_fn, device, n_examples):\n  model = model.eval()\n  losses = []\n  correct_predictions = 0\n  with torch.no_grad():\n    for d in data_loader:\n      input_ids = d[\"input_ids\"].to(device)\n      attention_mask = d[\"attention_mask\"].to(device)\n      targets = d[\"targets\"].to(device)\n      outputs = model(\n        input_ids=input_ids,\n        attention_mask=attention_mask\n      )\n      _, preds = torch.max(outputs, dim=1)\n      loss = loss_fn(outputs, targets)\n      correct_predictions += torch.sum(preds == targets)\n      losses.append(loss.item())\n  return correct_predictions.double() / n_examples, np.mean(losses)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T08:54:38.294859Z","iopub.execute_input":"2022-06-26T08:54:38.295298Z","iopub.status.idle":"2022-06-26T08:54:38.306127Z","shell.execute_reply.started":"2022-06-26T08:54:38.295258Z","shell.execute_reply":"2022-06-26T08:54:38.305144Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"%%time\nhistory = defaultdict(list)\nbest_accuracy = 0\nfor epoch in range(EPOCHS):\n  print(f'Epoch {epoch + 1}/{EPOCHS}')\n  print('-' * 10)\n  train_acc, train_loss = train_epoch(\n    model,\n    train_data_loader,\n    loss_fn,\n    optimizer,\n    device,\n    scheduler,\n    len(df_train)\n  )\n  print(f'Train loss {train_loss} accuracy {train_acc}')\n  val_acc, val_loss = eval_model(\n    model,\n    val_data_loader,\n    loss_fn,\n    device,\n    len(df_val)\n  )\n  print(f'Val   loss {val_loss} accuracy {val_acc}')\n  print()\n  history['train_acc'].append(train_acc)\n  history['train_loss'].append(train_loss)\n  history['val_acc'].append(val_acc)\n  history['val_loss'].append(val_loss)\n  if val_acc > best_accuracy:\n    torch.save(model.state_dict(), 'best_model_state.bin')\n    best_accuracy = val_acc","metadata":{"execution":{"iopub.status.busy":"2022-06-26T08:55:21.208844Z","iopub.execute_input":"2022-06-26T08:55:21.209217Z","iopub.status.idle":"2022-06-26T14:13:40.346405Z","shell.execute_reply.started":"2022-06-26T08:55:21.209185Z","shell.execute_reply":"2022-06-26T14:13:40.345157Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"hist={}\nhist['train_acc']=[y.cpu() for y in history['train_acc']]\nhist['val_acc']=[y.cpu() for y in history['val_acc']]\n#hist['train_loss']=[y.cpu() for y in history['train_loss']]\n#hist['val_loss']=[y.cpu() for y in history['val_loss']]","metadata":{"execution":{"iopub.status.busy":"2022-06-26T14:21:33.159296Z","iopub.execute_input":"2022-06-26T14:21:33.159669Z","iopub.status.idle":"2022-06-26T14:21:33.167746Z","shell.execute_reply.started":"2022-06-26T14:21:33.159637Z","shell.execute_reply":"2022-06-26T14:21:33.166596Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"plt.plot(hist['train_acc'], label='train accuracy')\nplt.plot(hist['val_acc'], label='validation accuracy')\nplt.title('Training history')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend()","metadata":{"execution":{"iopub.status.busy":"2022-06-26T14:21:42.881344Z","iopub.execute_input":"2022-06-26T14:21:42.881900Z","iopub.status.idle":"2022-06-26T14:21:43.219925Z","shell.execute_reply.started":"2022-06-26T14:21:42.881835Z","shell.execute_reply":"2022-06-26T14:21:43.219049Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"test_acc, _ = eval_model(\n  model,\n  test_data_loader,\n  loss_fn,\n  device,\n  len(df_test)\n)\ntest_acc.item()","metadata":{"execution":{"iopub.status.busy":"2022-06-26T14:22:18.624531Z","iopub.execute_input":"2022-06-26T14:22:18.625229Z","iopub.status.idle":"2022-06-26T14:27:25.593055Z","shell.execute_reply.started":"2022-06-26T14:22:18.625192Z","shell.execute_reply":"2022-06-26T14:27:25.592042Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"def get_predictions(model, data_loader):\n  model = model.eval()\n  review_texts = []\n  predictions = []\n  prediction_probs = []\n  real_values = []\n  with torch.no_grad():\n    for d in data_loader:\n      texts = d[\"text\"]\n      input_ids = d[\"input_ids\"].to(device)\n      attention_mask = d[\"attention_mask\"].to(device)\n      targets = d[\"targets\"].to(device)\n      outputs = model(\n        input_ids=input_ids,\n        attention_mask=attention_mask\n      )\n      _, preds = torch.max(outputs, dim=1)\n      review_texts.extend(texts)\n      predictions.extend(preds)\n      prediction_probs.extend(outputs)\n      real_values.extend(targets)\n  predictions = torch.stack(predictions).cpu()\n  prediction_probs = torch.stack(prediction_probs).cpu()\n  real_values = torch.stack(real_values).cpu()\n  return review_texts, predictions, prediction_probs, real_values","metadata":{"execution":{"iopub.status.busy":"2022-06-26T14:28:12.499772Z","iopub.execute_input":"2022-06-26T14:28:12.500175Z","iopub.status.idle":"2022-06-26T14:28:12.509396Z","shell.execute_reply.started":"2022-06-26T14:28:12.500141Z","shell.execute_reply":"2022-06-26T14:28:12.508359Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"y_review_texts, y_pred, y_pred_probs, y_test = get_predictions(\n  model,\n  test_data_loader\n)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T14:28:24.838252Z","iopub.execute_input":"2022-06-26T14:28:24.838607Z","iopub.status.idle":"2022-06-26T14:33:23.528766Z","shell.execute_reply.started":"2022-06-26T14:28:24.838574Z","shell.execute_reply":"2022-06-26T14:33:23.527569Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"print(classification_report(y_test, y_pred, target_names=['suicide','non-suicide']))","metadata":{"execution":{"iopub.status.busy":"2022-06-26T14:40:36.624873Z","iopub.execute_input":"2022-06-26T14:40:36.625247Z","iopub.status.idle":"2022-06-26T14:40:36.664982Z","shell.execute_reply.started":"2022-06-26T14:40:36.625216Z","shell.execute_reply":"2022-06-26T14:40:36.663986Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"def show_confusion_matrix(confusion_matrix):\n  hmap = sns.heatmap(confusion_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n  hmap.yaxis.set_ticklabels(hmap.yaxis.get_ticklabels(), rotation=0, ha='right')\n  hmap.xaxis.set_ticklabels(hmap.xaxis.get_ticklabels(), rotation=30, ha='right')\n  plt.ylabel('True sentiment')\n  plt.xlabel('Predicted sentiment');\ncm = confusion_matrix(y_test, y_pred)\ndf_cm = pd.DataFrame(cm, index=['suicide','non-suicide'], columns=['suicide','non-suicide'])\nshow_confusion_matrix(df_cm)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T14:41:32.462171Z","iopub.execute_input":"2022-06-26T14:41:32.462717Z","iopub.status.idle":"2022-06-26T14:41:32.819111Z","shell.execute_reply.started":"2022-06-26T14:41:32.462682Z","shell.execute_reply":"2022-06-26T14:41:32.818164Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport lime\nimport torch\nimport torch.nn.functional as F\nfrom lime.lime_text import LimeTextExplainer","metadata":{"execution":{"iopub.status.busy":"2022-06-26T14:54:37.514934Z","iopub.execute_input":"2022-06-26T14:54:37.515921Z","iopub.status.idle":"2022-06-26T14:54:37.521916Z","shell.execute_reply.started":"2022-06-26T14:54:37.515857Z","shell.execute_reply":"2022-06-26T14:54:37.520824Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"class_names=['suicide','non-suicide']\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification\n\nfilename_model = 'bert-base-uncased'\ntokenizer = AutoTokenizer.from_pretrained(filename_model)\nmodel = AutoModelForSequenceClassification.from_pretrained(filename_model)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T14:59:36.054401Z","iopub.execute_input":"2022-06-26T14:59:36.055340Z","iopub.status.idle":"2022-06-26T14:59:45.048410Z","shell.execute_reply.started":"2022-06-26T14:59:36.055285Z","shell.execute_reply":"2022-06-26T14:59:45.047383Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"def predictor(texts):\n    outputs = model(**tokenizer(texts, return_tensors=\"pt\", padding=True))\n    tensor_logits = outputs[0]\n    probas = F.softmax(tensor_logits).detach().numpy()\n    return probas","metadata":{"execution":{"iopub.status.busy":"2022-06-26T14:59:45.051020Z","iopub.execute_input":"2022-06-26T14:59:45.051424Z","iopub.status.idle":"2022-06-26T14:59:45.057564Z","shell.execute_reply.started":"2022-06-26T14:59:45.051383Z","shell.execute_reply":"2022-06-26T14:59:45.056130Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"df['text'][0]","metadata":{"execution":{"iopub.status.busy":"2022-06-26T14:59:45.060143Z","iopub.execute_input":"2022-06-26T14:59:45.060517Z","iopub.status.idle":"2022-06-26T14:59:45.069492Z","shell.execute_reply.started":"2022-06-26T14:59:45.060479Z","shell.execute_reply":"2022-06-26T14:59:45.068184Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"text = 'I am lonely and depressed'\nprint(tokenizer(text, return_tensors='pt', padding=True))\n\nexplainer = LimeTextExplainer(class_names=class_names)\nexp = explainer.explain_instance(text, predictor, num_features=6, num_samples=2000)\nexp.show_in_notebook(text=text)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T14:59:45.071874Z","iopub.execute_input":"2022-06-26T14:59:45.072795Z","iopub.status.idle":"2022-06-26T15:00:10.306423Z","shell.execute_reply.started":"2022-06-26T14:59:45.072751Z","shell.execute_reply":"2022-06-26T15:00:10.305154Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}